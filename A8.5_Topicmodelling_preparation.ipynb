{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load json file as dictionary\n",
    "import json\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "from umap import UMAP\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from bertopic import BERTopic\n",
    "import bertopic\n",
    "from hdbscan import HDBSCAN\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from bertopic.representation import KeyBERTInspired, MaximalMarginalRelevance, PartOfSpeech\n",
    "from bertopic.vectorizers import ClassTfidfTransformer\n",
    "import datamapplot\n",
    "import nbformat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/jy/j77v476x03737ryp7gll_0p00000gn/T/ipykernel_1094/1228290111.py:2: DtypeWarning: Columns (18,20,21,23,49,50) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  patents_text = pd.read_csv(\"patents_text_deduplicated.csv\")\n"
     ]
    }
   ],
   "source": [
    "unseen_data_labelled = pd.read_csv(\"unseen_data_predictions_20240704-114801.csv\")\n",
    "patents_text = pd.read_csv(\"patents_text_deduplicated.csv\")\n",
    "training_data = pd.read_csv(\"training_data_new3.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20445"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(patents_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19457"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unseen_data_labelled.publication_number_EPO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dictionaries for quick lookup, handling non-unique indices\n",
    "unseen_data_dict = unseen_data_labelled.drop_duplicates(subset='publication_number_EPO').set_index('publication_number_EPO')[['predicted_SofAI', 'predicted_AIforS']].to_dict(orient='index')\n",
    "training_data_dict = training_data.drop_duplicates(subset='publication_number_EPO').set_index('publication_number_EPO')[['SofAI', 'AIforS']].to_dict(orient='index')\n",
    "\n",
    "# Function to determine SofAI and AIforS values\n",
    "def get_values(pub_number):\n",
    "    if pub_number in unseen_data_dict:\n",
    "        return unseen_data_dict[pub_number]['predicted_SofAI'], unseen_data_dict[pub_number]['predicted_AIforS']\n",
    "    elif pub_number in training_data_dict:\n",
    "        return training_data_dict[pub_number]['SofAI'], training_data_dict[pub_number]['AIforS']\n",
    "    else:\n",
    "        return None, None\n",
    "\n",
    "# Apply the function to the patents_text dataframe\n",
    "patents_text['SofAI'], patents_text['AIforS'] = zip(*patents_text['publication_number_EPO'].apply(get_values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows with only SofAI set to 1: 548\n",
      "Number of rows with only AIforS set to 1: 17302\n",
      "Number of rows with both SofAI and AIforS set to 1: 2500\n",
      "Number of rows with neither SofAI nor AIforS set to 1: 95\n"
     ]
    }
   ],
   "source": [
    "# Count the occurrences for each category\n",
    "only_SofAI = ((patents_text['SofAI'] == 1) & (patents_text['AIforS'] == 0)).sum()\n",
    "only_AIforS = ((patents_text['SofAI'] == 0) & (patents_text['AIforS'] == 1)).sum()\n",
    "both = ((patents_text['SofAI'] == 1) & (patents_text['AIforS'] == 1)).sum()\n",
    "none = ((patents_text['SofAI'] == 0) & (patents_text['AIforS'] == 0)).sum()\n",
    "\n",
    "# Print the counts\n",
    "print(f\"Number of rows with only SofAI set to 1: {only_SofAI}\")\n",
    "print(f\"Number of rows with only AIforS set to 1: {only_AIforS}\")\n",
    "print(f\"Number of rows with both SofAI and AIforS set to 1: {both}\")\n",
    "print(f\"Number of rows with neither SofAI nor AIforS set to 1: {none}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "patents_text.to_csv(\"patents_text_topic_modelling2.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bertopic_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
